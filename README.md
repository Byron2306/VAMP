# ğŸ§  VAMP Agent â€” Visual AI Metadata Parser

## Overview

The **VAMP Agent** is a stealthy, browser-based deep content analysis tool that scrapes, reads, scores, and normalizes information from platforms like:
- ğŸ“§ Outlook / Office365
- â˜ï¸ OneDrive
- ğŸ§¾ Google Drive
- ğŸŒ NextCloud
- ğŸ“ eFundi LMS

It uses **Playwright** for authenticated browser automation, **NWU Brain** for scoring extracted evidence, and a **WebSocket bridge** for frontend-extension integration.

---

## ğŸ— System Architecture

```txt
Browser Extension â†” backend.ws_bridge â†” backend.vamp_agent â†” NWU Brain (scoring)
                          â†‘
                 backend.deepseek_client (Ollama)
```

---

## ğŸ“‚ Repository Layout

```
VAMP/
â”œâ”€â”€ README.md
â”œâ”€â”€ backend/                   # Python backend package
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ nwu_brain/         # Scoring manifest + policy knowledge base
â”‚   â”‚   â”œâ”€â”€ states/            # Browser storage state (created at runtime)
â”‚   â”‚   â””â”€â”€ store/             # User evidence store (created at runtime)
â”‚   â”œâ”€â”€ nwu_brain/             # NWU scorer implementation
â”‚   â”œâ”€â”€ deepseek_client.py
â”‚   â”œâ”€â”€ vamp_agent.py
â”‚   â”œâ”€â”€ vamp_master.py
â”‚   â”œâ”€â”€ vamp_runner.py
â”‚   â”œâ”€â”€ vamp_store.py
â”‚   â””â”€â”€ ws_bridge.py
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ extension/             # Chrome extension source (incl. icons/, sounds/)
â”œâ”€â”€ requirements.txt
â””â”€â”€ scripts/
    â”œâ”€â”€ setup_backend.ps1
    â””â”€â”€ setup_backend.bat
```

---

## ğŸš€ Features

- ğŸ” Uses live authenticated sessions (via persistent browser contexts)
- ğŸ§  Full content scraping + keyword scoring
- ğŸ“œ Auto-scroll & deep content extraction
- ğŸ’¾ Saves storage states (no repeated login)
- ğŸ” Works with Google, Microsoft, Sakai platforms
- ğŸ§° Integrated with NWU's custom scoring engine
- ğŸ§© Injects the full NWU brain corpus (charter, routing, policies, scoring, values) into every DeepSeek/Ollama prompt
- ğŸ§¾ Emits per-scan evidence counts to simplify "zero result" troubleshooting
- ğŸ§± Modular design: easy to extend per platform

---

## ğŸ§ª Setup Instructions

### 1. âœ… Prerequisites

- Python 3.10+
- Chrome installed (uses your live profile)
- `Playwright` + browser dependencies installed

### 2. ğŸ›  Install Requirements

```bash
pip install -r requirements.txt
playwright install
```

### 3. ğŸ§¬ Set Environment Variables

```powershell
$env:DEEPSEEK_API_URL = "http://127.0.0.1:11434/v1/chat/completions"
$env:DEEPSEEK_MODEL   = "gpt-oss:120b-cloud"

# Optional Ollama cloud overrides
$env:OLLAMA_API_URL   = "https://api.ollama.cloud/api/chat"
$env:OLLAMA_MODEL     = "gpt-oss:120b"
$env:OLLAMA_API_KEY   = "<token>"
```

> `deepseek_client.py` will automatically detect Ollama-style endpoints (`/api/chat` or `/api/generate`) and adjust the payload/headers. If you only set the Ollama variables, the DeepSeek defaults are ignored.

### Headless Outlook / OneDrive / Google Drive login

To keep Chromium hidden while still authenticating, provide service credentials via environment variables before starting the backend:

```bash
export VAMP_OUTLOOK_USERNAME="user@nwu.ac.za"
export VAMP_OUTLOOK_PASSWORD="<app-password-or-sso-secret>"
export VAMP_ONEDRIVE_USERNAME="user@nwu.ac.za"   # optional, defaults to email argument
export VAMP_ONEDRIVE_PASSWORD="<password>"
export VAMP_GOOGLE_USERNAME="user@nwu.ac.za"
export VAMP_GOOGLE_PASSWORD="<password>"
```

When these are present the Playwright agent attempts a full headless login, captures a persistent storage state, and skips the manual Chromium window entirely. If the automated login fails or credentials are omitted the previous interactive flow is used as a fallback.

---

## ğŸ§  Usage

### Start the backend WebSocket bridge:

```bash
python -m backend.ws_bridge
```

It will:
- Listen for frontend requests
- Trigger scans via `run_scan_active`
- Return scored, deduped results

> Runtime data (Chrome storage states and evidence store) is written to `backend/data/states/<service>/<user>.json` and `backend/data/store/`.

---

## ğŸ’¡ Example Scan Flow

1. Frontend triggers `"scanActive"` with:
   ```json
   {
     "action": "scanActive",
     "email": "user@nwu.ac.za",
     "url": "https://outlook.office365.com/mail/",
     "year": 2025,
     "month": 11
   }
   ```
2. Backend invokes `run_scan_active(...)`
3. Browser is launched and logs into Outlook using session state
4. Emails are parsed, filtered, scored and returned to the frontend

---

## ğŸ§ª Supported Platforms

| Platform   | Status | Notes                             |
|------------|--------|-----------------------------------|
| Outlook    | âœ…     | MFA/login handled manually first  |
| OneDrive   | âœ…     | Uses state restore for auth       |
| GoogleDrive| âœ…     | Uses persistent context           |
| eFundi     | âœ…     | No auth needed                    |
| NextCloud  | âš ï¸     | Placeholder - manual add required |

---

## ğŸ“ Key Files

| File / Folder                        | Description                                 |
|--------------------------------------|---------------------------------------------|
| `backend/vamp_agent.py`              | Core scraping + Playwright automation       |
| `backend/ws_bridge.py`               | WebSocket bridge to frontend                |
| `backend/deepseek_client.py`         | Client to LLM API via Ollama                |
| `backend/nwu_brain/scoring.py`       | Loads NWU brain manifest + scoring logic    |
| `backend/data/nwu_brain/*.json`      | Manifest, policy registry, routing rules    |
| `backend/data/states/`               | Chrome storage states (generated at runtime)|
| `backend/data/store/`                | Evidence store per user (generated)         |

---

## ğŸ§  NWU Brain Scoring

All extracted items are passed to the `NWUScorer` which assigns:

- `kpa`: Key Performance Area
- `tier`: Risk/priority tier
- `score`: Numerical score
- `band`: Banding (e.g. "Developing")
- `policy_hits`: Keyword/policy matches

---

## ğŸ›¡ Authentication

The system **does not use OAuth**.
- Instead, it authenticates via **live Chrome profile**.
- First-time use requires manual login in browser.
- Persistent state is saved for reuse:
  - `outlook_state.json`
  - `onedrive_state.json`
  - `drive_state.json`

---

## ğŸ§° Debugging Tips

- âœ… Ensure `playwright install` is complete
- âœ… Always launch with `python -m backend.ws_bridge`
- ğŸ”’ Check for blocked browser login prompts
- ğŸ§ª Use `--headless=False` in `BROWSER_CONFIG` to see browser
- ğŸ§ª Logs appear in terminal: scan status, scoring feedback

---

## ğŸ”§ Developer Tips

- Modify `backend/vamp_agent.py` to add new platforms
- Adjust selectors in `scrape_*` functions
- Use `logger.info()` to trace progress
- Patch in `backend/data/nwu_brain/` for updated policies or scoring

---

## ğŸ§¾ License

Internal use only â€“ NWU Research and Policy Development.

---

## ğŸ§  Credits

Built with â¤ï¸ using:
- Microsoft Playwright
- Python 3.10
- Ollama LLM (DeepSeek-V2)
- NWUâ€™s brain.json and scoring logic
